{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GEMINI_API_KEY'] = 'Enter your api key hear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=os.environ['GEMINI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = genai.GenerativeModel('gemini-1.5-flash')\\\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"what is life span of person.\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-2.0-pro-exp-02-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = model.generate_content(\"What is the meaning of dream & goal? how to reach the dream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.prompt_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in response:\n",
    "  print(chunk.text)\n",
    "  #print(\"_\"*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "img = PIL.Image.open(r'C:\\Users\\A3MAX SOFTWARE TECH\\A VS CODE\\9. Gemini AI\\team.jpeg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('models/gemini-2.0-pro-exp-02-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(img)\n",
    "\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "img1 = PIL.Image.open(r'C:\\Users\\A3MAX SOFTWARE TECH\\A VS CODE\\9. Gemini AI\\horse.jpg')\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = model.generate_content(img1)\n",
    "\n",
    "to_markdown(response1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img], stream=True)\n",
    "response.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('models/gemini-2.0-pro-exp-02-05')\n",
    "chat = model.start_chat(history=[])\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\"In one sentence, explain how a computer works to a young child.\")\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\"Okay, how about a more detailed explanation to a high schooler?\", stream=True)\n",
    "\n",
    "for chunk in response:\n",
    "  print(chunk.text)\n",
    "  print(\"_\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in chat.history:\n",
    "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_tokens(\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_tokens(chat.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=\"What is the meaning of life?\",\n",
    "    task_type=\"retrieval_document\",\n",
    "    title=\"Embedding of single string\")\n",
    "\n",
    "# 1 input > 1 vector output\n",
    "print(str(result['embedding'])[:50], '... TRIMMED]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=[\n",
    "      'What is the meaning of life?',\n",
    "      'How much wood would a woodchuck chuck?',\n",
    "      'How does the brain work?'],\n",
    "    task_type=\"retrieval_document\",\n",
    "    title=\"Embedding of list of strings\")\n",
    "\n",
    "# A list of inputs > A list of vectors output\n",
    "for v in result['embedding']:\n",
    "  print(str(v)[:50], '... TRIMMED ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.candidates[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "    model = 'models/text-embedding-004',\n",
    "    content = response.candidates[0].content)\n",
    "\n",
    "# 1 input > 1 vector output\n",
    "print(str(result['embedding'])[:50], '... TRIMMED ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content('[Questionable prompt here]')\n",
    "response.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.prompt_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content('[Questionable prompt here]',\n",
    "                                  safety_settings={'HARASSMENT':'block_none'})\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(\n",
    "    genai.protos.Content(\n",
    "        parts = [\n",
    "            genai.protos.Part(text=\"Write a short, engaging blog post based on this picture.\"),\n",
    "            genai.protos.Part(\n",
    "                inline_data=genai.protos.Blob(\n",
    "                    mime_type='image/jpg',\n",
    "                    data=pathlib.Path(r'C:\\Users\\A3MAX SOFTWARE TECH\\Desktop\\WORK\\1. KODI WORK\\1. NARESH\\10. WORKSHOP\\7. Exploring Generative AI through computer vision/myimage.jpg').read_bytes()\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.resolve()\n",
    "\n",
    "to_markdown(response.text[:100] + \"... [TRIMMED] ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.resolve()\n",
    "\n",
    "to_markdown(response.text[:100] + \"... [TRIMMED] ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "messages = [\n",
    "    {'role':'user',\n",
    "     'parts': [\"Briefly explain how a computer works to a young child.\"]}\n",
    "]\n",
    "response = model.generate_content(messages)\n",
    "\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({'role':'model',\n",
    "                 'parts':[response.text]})\n",
    "\n",
    "messages.append({'role':'user',\n",
    "                 'parts':[\"Okay, how about a more detailed explanation to a high school student?\"]})\n",
    "\n",
    "response = model.generate_content(messages)\n",
    "\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(\n",
    "    'Tell me a story about a magic backpack.',\n",
    "    generation_config=genai.types.GenerationConfig(\n",
    "        # Only one candidate for now.\n",
    "        candidate_count=1,\n",
    "        stop_sequences=['x'],\n",
    "        max_output_tokens=20,\n",
    "        temperature=1.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = response.text\n",
    "\n",
    "if response.candidates[0].finish_reason.name == \"MAX_TOKENS\":\n",
    "    text += '...'\n",
    "\n",
    "to_markdown(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
